{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "(â•¯Â°â–¡Â°)â•¯ï¸µâ—“\n",
    "\n",
    "You've been search far and wide, but you're still trying to understand the power that's inside. This time round though, you're armed with new weapons: supervised learning algorithms. Pokemons will have no more secrets after you analyse the pokedex!\n",
    "\n",
    "The data can be found under `pokedex/pokemons.csv`, and is the same as assignment 1 & 2. Run the cell below to get an overview of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pokedex/pokemons.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A crucial statistic in pokemon battles is `HP`. This is the amount of damage you have to inflict to your opponent to win the fight, so being able to _predict_ this amount would be an enormous advantage ðŸ‘Š.\n",
    "\n",
    "ðŸ’ª **Task: Train a linear regression model which predicts the label `HP`.**\n",
    "- use `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed` as features\n",
    "- use `HP` as label\n",
    "- scale the features using standardization before you train the model\n",
    "- store your trained model in a variable called `reg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Linear Regression Model.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Defining Essentials for our Model.\n",
    "linear_features = df[['Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']]\n",
    "linear_labels = df['HP']\n",
    "\n",
    "#Defining the features and labels in terms of Matrix X and vector y.\n",
    "#Reshaping isn't required in our case as we have the appropriate formatting present already.\n",
    "linear_X = linear_features.values\n",
    "linear_y = linear_labels.values\n",
    "\n",
    "# Importing Standard Scaler to scale our features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fitting our Features through the Scaler.\n",
    "linear_scaler = StandardScaler().fit(linear_X)\n",
    "linear_scaled_features = linear_scaler.transform(linear_X)\n",
    "\n",
    "#Training and Storing our Data at 'reg'\n",
    "reg = LinearRegression().fit(linear_scaled_features, linear_y)\n",
    "\n",
    "#Getting Predictions of label HP.\n",
    "PredictedHP = reg.predict(linear_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def test_regression():\n",
    "    assert reg, \"Can't find reg, have you used the correct variable name for your model?\"\n",
    "    assert math.isclose(reg.coef_.sum(), 15.20036, rel_tol=1e-6), \"Your model parameters don't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "\n",
    "test_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Task: List and describe the main steps that happen during your linear regression model's _training_ , i.e inside of sklearn's `.fit()` method.**\n",
    "\n",
    "ðŸ§  **Task: Explain the purpose of feature scaling, and why it's a good idea to use it here.**\n",
    "\n",
    "ðŸ§  **Bonus Task: Can you list other feature scaling methods?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ ***Answer 1:*** Passing the features through the `.fit()` method results in an optimized and comparable output using gradient descent optimization. The `.fit()` method:\n",
    "\n",
    "* Starts with random parameters of **$\\theta$** for all the features in the calculation model. ***(Multi-variate Linear Regression in the case above.)***\n",
    "* Then determines a function ***J*** which is the cost in regards to our model and its features.\n",
    "* Calculates the derivative of our cost function ***J*** at these intial parameters ***($\\frac{dJ}{d\\theta}$)***.\n",
    "* A proportional step is taken to the negative of the derivative. This is done to accurately determine the minimum points in our function ***($-\\alpha \\frac{dJ}{d\\theta}$)***.\n",
    "* Redetermining the cost function and repeating it all ahead until we reach a minimum point ***($\\frac{dJ}{d\\theta} \\approx 0$)***.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ ***Answer 2:*** So `feature scaling` allows us to get more get data of varying scales and adjust it as such that we avoid having possible biases from big outliers in our comparisons.\n",
    "\n",
    "In our case, we use sklearn's `StandardScaler` which uses ***standardization***. This involves transforming the data in such a manner that the `mean` becomes **0** and the `variance` becomes **1**. Now the data is presented in a much more smaller, comparable scale with higher accuracy while still being proportional to the actual values of the data.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ðŸŽ‰ ***Bonus Answer:*** Below is a list of a few feature scaling methods.\n",
    "\n",
    "* **Standardization:** Discussed above. (Great if the data is normally distributed.)\n",
    "* **Normalization *(also called Min Max Scaling)*:** Normalization involves taking the feautres and binding its them within a specific range such as [0,1] or [-1,1]. (Great if the standard deviation is small.)\n",
    "* **Maximum Absolute Scaling:** Scales each feature individually that the maximum absolute value of those features are equal to `1.0`. The data is never shifted or centered and the sparsity of data remains.\n",
    "* **Robust Scaling:** Used when data contains many outliers. Uses `Quantile Ranges` *(25th, 75th)* to remove the median and scales of the data. Using quantiles for medians and centering reduces the influence of the few huge marginal outliers in the data and a more accurate scaling in achieved in comparison to the mean and standard methods.\n",
    "\n",
    "> These are a few that I could logically understand out of all the ones I found in my research online. There might be more easier ones or tougher ones remaining but my submission this time will really close to the set deadline.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "You encounter an unknown pokemon, and it looks very strong. ðŸ™€ Use your `HP` regression model to see if you can take it on!\n",
    "\n",
    "ðŸ’ª **Task: Predict the `HP` of an unknown pokemon using your linear regression model.**\n",
    "- the stats of the unknown pokemon are found below\n",
    "- predict using your trained model, `reg`\n",
    "- store the prediction in a variable called `y_predict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.55099276])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack = 79\n",
    "defense = 109\n",
    "sp_atk = 73\n",
    "sp_def = 84\n",
    "speed = 68\n",
    "\n",
    "#The stats of the pokemon shall be taken as the feature and written in the form of a Numpy array.\n",
    "unknown_pokemon = np.array([attack, defense, sp_atk, sp_def, speed])\n",
    "\n",
    "#Now features must be a matrix and we have array so we reshape it into the desired size of the matrix.\n",
    "unknown_pokemon_feature = unknown_pokemon.reshape(1,5)\n",
    "\n",
    "#Scaling up this feature so it is accurately to our existing scaled and regressed data.\n",
    "unknown_pokemon_feature_scaled = linear_scaler.transform(unknown_pokemon_feature)\n",
    "\n",
    "#Scaled Feature is ready for prediction so running it through reg.predict and storing in variable 'y_predict'\n",
    "y_predict = reg.predict(unknown_pokemon_feature_scaled)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_predict_hp():\n",
    "    expected_prediction = 69.551\n",
    "    assert y_predict, f\"Can't find y_predict, have you used the correct variable name?\"\n",
    "    assert math.isclose(y_predict, expected_prediction, rel_tol=1e-4), f'The prediction should be {expected_prediction}, but your model predicted {y_predict}'\n",
    "    print('Success! ðŸŽ‰')\n",
    "    return\n",
    "\n",
    "test_predict_hp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Professor Oak told you about a rare breed of exceptionally powerful pokemon... the _legendary_ pokemon. A trainer who finds and captures a legendary pokemon is sure to become invicible!\n",
    "\n",
    "ðŸ’ª **Task: Train a logistic regression model which predicts if pokemons are `Legendary`.**\n",
    "- use `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed` as features\n",
    "- use `Legendary` as label\n",
    "- scale the features using standardization before you train the model\n",
    "- store your trained model in a variable called `clf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Logistic Regression Model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Standard Scaler pre-imported in Problem 1. \n",
    "#Defining Essentials of our Model.\n",
    "logistic_features = df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']]\n",
    "logistic_labels = df['Legendary']\n",
    "\n",
    "#Defining features and labels in terms of Matrix X and vector y\n",
    "logistic_X = logistic_features.values\n",
    "logistic_y = logistic_labels.values\n",
    "\n",
    "#Scaling and Standardizing our features.\n",
    "logistic_scaler = StandardScaler().fit(logistic_X)\n",
    "logistic_scaled_features = logistic_scaler.transform(logistic_X)\n",
    "\n",
    "#Training and Storing our Data at 'clf'\n",
    "clf = LogisticRegression().fit(logistic_scaled_features, logistic_y)\n",
    "\n",
    "#Getting Predictions of label 'Legendary' based on standardized features.\n",
    "PredictedLegendary = clf.predict(logistic_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_regression():\n",
    "    assert clf, \"Can't find clf, have you used the correct variable name for your model?\"\n",
    "    assert math.isclose(clf.coef_.sum(), 5.80924, rel_tol=1e-5), \"Your model parameters don't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "    return\n",
    "\n",
    "test_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Task: What are the differences between logistic regression and linear regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ ***Answer 3:***\n",
    "\n",
    "| **Linear Regression** | **Logistic Regression** |\n",
    "| --- | --- |\n",
    "| Predicts a ***Continuous*** Dependent Variable based on the values of the Independent variables | Predicts a ***Categorical*** Dependent Variable based on the values of the Independent Variable |\n",
    "| Estimated on the ***least square*** (the regression coefficients are chosen such that they minimize the sum of the square distance between each of the observed responses | Estimated on the ***maximum likelihood*** (the regression coefficients are chosen such that the probability of *y* under given values *X* is maximized) |\n",
    "| Best represented in the form of a ***Straight Line*** | Best represented in the form of a ***Curve*** |\n",
    "| The Dependent and Independent variables ***have*** a linear relationship | The Dependent and Independent variables ***may or may not have*** a linear relationship |\n",
    "| Resultant Output is a ***Predicted Integer Value*** | Resultant Output is a ***Predicted Binary Value*** |\n",
    "\n",
    "> `Extra`\n",
    "- **Common Application of Linear Regression:** Forecasting Sales in Business Models.\n",
    "- **Common Application of Logistic Regression:** Classification Problems and Image Processing.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Problem 4\n",
    "\n",
    "Finding legendary pokemons is no easy task, and we expect that we need a more _powerful_ model to accurately predict them.\n",
    "\n",
    "ðŸ’ª **Task: Train a logistic regression model with polynomial features and regularization which predicts if pokemons are Legendary.**\n",
    "- use `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed` as features\n",
    "- use `Legendary` as label\n",
    "- add polynomial features of degree 3\n",
    "- scale the features using standardization before you train the model\n",
    "- use ridge logistic regression to regularize your model\n",
    "- store your trained model in a variable called `clf`  \n",
    "Pro-tip: [RidgeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression Pre-Imported in Problem 1.\n",
    "#Logistic Regression Pre-Imported in Problem 3.\n",
    "#Standard Scaler Pre-Imported in Problem 1.\n",
    "\n",
    "#Importing Polynomial Features Pre-processing.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Importing Ridge Classification Model.\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "#Defining Essentials of our Model\n",
    "pologreg_features = df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']]\n",
    "pologreg_labels = df['Legendary']\n",
    "\n",
    "#Defining Features in Terms of Matrix X and Vector y.\n",
    "pologreg_X = pologreg_features.values\n",
    "pologreg_y = pologreg_labels.values\n",
    "\n",
    "#Using Polynomial Features to add features of degree 3.\n",
    "pologreg_poly = PolynomialFeatures(3, include_bias = False)\n",
    "pologreg_poly = pologreg_poly.fit(pologreg_X)\n",
    "X_pologreg_poly = pologreg_poly.transform(pologreg_X)\n",
    "\n",
    "#Scaling and Standardizing features with added Polynomials.\n",
    "pologreg_scaler = StandardScaler()\n",
    "pologreg_scaler = pologreg_scaler.fit(X_pologreg_poly)\n",
    "X_pologreg_poly_scaled = pologreg_scaler.transform(X_pologreg_poly)\n",
    "\n",
    "#Using Ridge Logistic Regression to Regularize the Model.\n",
    "pologreg_reg = RidgeClassifier(alpha=1).fit(X_pologreg_poly_scaled, pologreg_y)\n",
    "\n",
    "#Taking this value and sending it to 'clf' as per question requirement.\n",
    "clf = pologreg_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_regression():\n",
    "    assert clf, \"Can't find clf, have you used the correct variable name for your model?\"\n",
    "    assert math.isclose(clf.coef_.sum(), 0.37331, rel_tol=1e-5), \"Your model parameters don't look quite right\"\n",
    "    print('Success! ðŸŽ‰')\n",
    "    return\n",
    "\n",
    "test_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  **Task: How do polynomial features make our model more powerful?**\n",
    "\n",
    "ðŸ§  **Task: What is the purpose of regularization? Why is it a good idea to use it here?**\n",
    "\n",
    "ðŸ§  **Bonus Task: Can you cite other regularization methods?**\n",
    "\n",
    "ðŸ’ª **Bonus Task: Train the exact same regularized logistic regression model with polynomial features, but this time, chain your preprocessors and your model into a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ ***Answer 4:*** Polynomial Features are used to create additional features by taking the polynomial of to a respective degree of the features. This allows for more variance and hence get an even more accurate regression model in proportion to the the higher the degree of the additional polynomial features.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ ***Answer 5:***  Regularization is used to reduce the chances of error by fitting a function appropriately on the given training set and avoiding overfitting. Datapoints of the features can be divided into two broad categories: \n",
    "- `Pattern`\n",
    "- `Noise`\n",
    "\n",
    "The end goal of using regularization is to have a training model with the most accurate estimations based on algortihms from the `Pattern` datapoints while ignoring the `Noise`. This is done by taking higher degree polynomials of our data points and factoring them in and then comparing it with the previous, simpler one in order to reduce the factor of the noise inside the data. Noise cannot be completely terminated but it can certainly be reduced by artificially penalizing it high degree polynomials of the features.\n",
    "\n",
    "In our case, the datapoints are in such varying ranges with some possible outliers which would affect the regression model. Regularization ensures that we get an accurate model with the added information from higher degree Polynomials and their comparisons to factor out the noise in the datapoints such as our outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "You are travelling across the land, when you spot a large rainbow bird in the sky. Maybe it's a legendary pokemon! Let's check with our freshly trained regularized polynomial classifier.\n",
    "\n",
    "ðŸ’ª **Task: Predict if the rainbow bird is a legendary pokemon using your classifier.**\n",
    "- the stats of the rainbow bird pokemon are found below\n",
    "- predict using your trained model, `clf`\n",
    "- store the prediction in a variable called `y_predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 106\n",
    "attack = 130\n",
    "defense = 90\n",
    "sp_atk = 110\n",
    "sp_def = 154\n",
    "speed = 90\n",
    "\n",
    "#Using Defined Stats and making it into an array.\n",
    "rainbow_pokemon_stats = np.array([hp, attack, defense, sp_atk, sp_def, speed])\n",
    "\n",
    "#Reshaping the Array so it is in a matrix form.\n",
    "rainbow_pokemon_features = rainbow_pokemon_stats.reshape(1,6)\n",
    "\n",
    "#Adding the same polynomial features to the Rainbow Pokemon's features.\n",
    "rainbow_pokemon_pologreg_poly = pologreg_poly.transform(rainbow_pokemon_features)\n",
    "\n",
    "#Scaling and Standardizing the Rainbow Pokemon's features for an accurate prediction.\n",
    "rainbow_pokemon_pologreg_scaled = pologreg_scaler.transform(rainbow_pokemon_pologreg_poly)\n",
    "\n",
    "#Storing Prediction in a variable 'y_predict'.\n",
    "y_predict = clf.predict(rainbow_pokemon_pologreg_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "def test_predict_legendary():\n",
    "    assert y_predict == True, f'The prediction should be {True}, but your model predicted {y_predict}'\n",
    "    print('Success! ðŸŽ‰')\n",
    "    \n",
    "test_predict_legendary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
